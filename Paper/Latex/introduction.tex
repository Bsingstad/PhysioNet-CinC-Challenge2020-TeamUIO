Cardiovascular diseases are one of the leading causes of death in the world. Numbers from WHO estimate that $17.9$ million people died from cardiovascular death (CVD) in 2016 which represented $31\%$ of all global deaths that year \cite{noauthor_cardiovascular_nodate}. Early detection of patients with a risk of CVD could potentially decrease the amount of CVD. Electrocardiography is a method already in use to detect cardiac-related pathology that may be related to CVD but probably has the potential to detect even more \cite{schlapfer_computer-interpreted_2017}. The electrocardiograph is non-invasive and relatively easy to use, compared to methods like echocardiogram and MRI, which makes it a convenient diagnostic tool. As an example of how widely the electrocardiograph is used, National Ambulatory Medical Care reported that 40 million electrocardiograms (ECG) were recorded in the USA in 2015 \cite{us_department_of_health_and_human_services_national_2015}.

An electrocardiograph measures the electrical activity of the heart from electrodes placed on the surface of the upper body. The result of such a measurement is an ECG. The ECG is a graphical representation of the measured electrical activity of the heart with respect to time. One of the challenges is that the ECG can be difficult to interpret correctly. The interpretation can be time-consuming and require a high degree of expertise \cite{bickerton_misplaced_2019}.

Many of the modern and clinically used electrocardiographs today are equipped with a built-in interpretation program. The interpretation program analyzes the ECG and prints interpretive texts that may indicate different pathologies. Studies show that there are some limitations to the automatic interpretation algorithms \cite{schlapfer_computer-interpreted_2017, smulyan_computerized_2019}. The errors, caused by the automatic interpretation algorithms, imply  that doctors or cardiologists have to read over the ECGs to ensure they are correct.



A considerable amount of literature has been published on heartbeat classification \cite{annam_classification_2020}, single \cite{mathews_novel_2018} and even  2-lead classification \cite{liu_arrhythmia_2013} over the last ten years. In most recent years there has been an increasing focus on 12-lead ECG classification and some recent studies have shown that machine learning is feasible \cite{ribeiro_automatic_2020, yao_multi-class_2020,li_automatic_2020, chen_detection_2020}. On the other hand, the  dataset used has either been small and homogeneous \cite{noauthor_classification_nodate} or not accessible to everyone. In this study, a large, open dataset from several sources and a large variation in different diagnoses will be examined and used as a development set for training machine learning models \cite{alday_classification_2020}. This dataset was used in a challenge held by PhysioNet \cite{goldberger_physiobank_2000} and Computing in Cardiology (CinC) in 2020 where $217$ teams submitted $1395$ algorithms during the challenge \cite{alday_classification_2020}. A training set and a test set were provided and the team who got the best score on the test set won the competition. The best team called themselves \textit{prna} and they achieved a PhysioNet/CinC Challenge score \cite{alday_classification_2020} of $0.533$ on the test set and a cross-validated score of $0.533\pm 0.046$. 

In this research, eight machine learning models from a previous study \cite{singstad_convolutional_nodate} will be evaluated and compared with two new machine learning models.  One of the two new models will utilize features from 12 leads and the other will utilize features from only 2 leads. 

It is already stated that PhysioNet/CinC Challenge 2021 will utilize the same dataset, but this time investigate both 12-lead and 2-lead ECGs in a challenge called "will 2 to?". One of the objectives of this study is to prepare an initial submission to the PhysioNet/CinC Challenge 2021 which will go live at the end of December 2020.

In addition, this study will demonstrate how to explain the predictions from the machine learning models developed in this study. The models used in this study are typical examples of what has been considered as black boxes. Explainability of such models is a new and emerging field in artificial intelligence (AI) and is called explainable AI. An explanation is important for complying with the rights that the GDPR gives regarding the right of human intervention. In medical application, there is also a need for knowing what the decision is based on and if it can be explained physiologically. Explainable predictions of machine learning models will probably lead to better trustworthiness  among doctors and health workers. 